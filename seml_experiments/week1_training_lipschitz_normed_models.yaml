# Experiment configuration file.
#
# There are two special blocks. The 'seml' block is required for every experiment.
# It has to contain the following values:
# executable:        Name of the Python script containing the experiment. The path should be relative to the `project_root_dir`.
#                    For backward compatibility SEML also supports paths relative to the location of the config file.
#                    In case there are files present both relative to the project root and the config file,
#                    the former takes precedence.
# It can optionally also contain the following values:
# name:              Prefix for output file and Slurm job name. Default: Collection name
# output_dir:        Directory to store log files in. Default: Current directory
# conda_environment: Specifies which Anaconda virtual environment will be activated before the experiment is executed.
#                    Default: The environment used when queuing.
# project_root_dir:  (Relative or absolute) path to the root of the project. seml will then upload all the source
#                    files imported by the experiment to the MongoDB. Moreover, the uploaded source files will be
#                    downloaded before starting an experiment, so any changes to the source files in the project
#                    between queueing and starting the experiment will have no effect.
#
# The special 'slurm' block contains the slurm parameters. This block and all values are optional. Possible values are:
# experiments_per_job:     Number of parallel experiments to run in each Slurm job.
#                          Note that only experiments from the same batch share a job. Default: 1
# max_simultaneous_jobs:   Maximum number of simultaneously running Slurm jobs per job array. Default: No restriction
# sbatch_options_template: Name of a custom template of `SBATCH` options. Define your own templates in `settings.py`
#                          under `SBATCH_OPTIONS_TEMPLATES`, e.g. for long-running jobs, CPU-only jobs, etc.
# sbatch_options:          dictionary that contains custom values that will be passed to `sbatch`, specifying e.g.
#                          the memory and number of GPUs to be allocated (prepended dashes are not required). See
#                          https://slurm.schedmd.com/sbatch.html for all possible options.
#
# Parameters under 'fixed' will be used for all the experiments.
#
# Under 'grid' you can define parameters that should be sampled from a regular grid. Options are:
#   - choice:     List the different values you want to evaluate under 'choices' as in the example below.
#   - range:      Specify the min, max, and step. Parameter values will be generated using np.arange(min, max, step).
#   - uniform:    Specify the min, max, and num. Parameter values will be generated using
#                 np.linspace(min, max, num, endpoint=True)
#   - loguniform: Specify min, max, and num. Parameter values will be uniformly generated in log space (base 10).
#
# Under 'random' you can specify parameters for which you want to try several random values. Specify the number
# of samples per parameter with the 'samples' value as in the examples below.
# Specify the the seed under the 'random' dict or directly for the desired parameter(s).
# Supported parameter types are:
#   - choice:      Randomly samples <samples> entries (with replacement) from the list in parameter['options']
#   - uniform:     Uniformly samples between 'min' and 'max' as specified in the parameter dict.
#   - loguniform:  Uniformly samples in log space between 'min' and 'max' as specified in the parameter dict.
#   - randint:     Randomly samples integers between 'min' (included) and 'max' (excluded).
#
# The configuration file can be nested (as the example below) so that we can run different parameter sets
# e.g. for different datasets or models.
# We take the cartesian product of all `grid` parameters on a path and sample all random parameters on the path.
# The number of random parameters sampled will be max{n_samples} of all n_samples on the path. This is done because
# we need the same number of samples from all random parameters in a configuration.
#
# More specific settings (i.e., further down the hierarchy) always overwrite more general ones.


seml:
  executable: training_experiments.py
  name: week1_training_lipschitz_normed_models
  output_dir: ../seml_outputs/week1_training_lipschitz_normed_models
  project_root_dir: ..

slurm:
  experiments_per_job: 1
  sbatch_options:
    gres: gpu:0       # num GPUs
    mem: 16G          # memory
    cpus-per-task: 1  # num cores
    time: 0-08:00     # max time, D-HH:MM

###### BEGIN PARAMETER CONFIGURATION ######

fixed:
  training.early_stopping_patience: 100
  training.num_epochs: 10000
  data.num_dataset_splits : 10
  data.train_portion : 0.05
  data.val_portion : 0.15
  data.test_portion : 0.6
  data.test_portion_fixed : 0.2
  model.weight_scale : 5
  model.num_initializations : 50
  model.use_bias: true
  model.activation: leaky_relu
  model.leaky_relu_slope: 0.01

grid:
  optimization.learning_rate:
    type: choice
    options:
      - 1e-2
    # type: loguniform
    # min: 1e-5
    # max: 1e-1
    # num: 5
  data.dataset:
    type: choice
    options:
      - cora_ml
      # - citeseer
      # - pubmed
  model.hidden_sizes:
    type: choice
    options:
      - [16]
      # - [32]
      # - [64]
      # - [16, 16]
      # - [32, 32]
      # - [64, 64]
  model.use_spectral_norm:
      type: choice
      options:
        - true
      #  - false
gat:
  fixed:
    model.model_type: gat
  grid:
    model.num_heads:
      type: choice
      options:
        - 1
        # - 2
        # - 4
        # - 8
# gcn:
#   fixed:
#     model.model_type: gcn
# gin:
#   fixed:
#     model.model_type: gin
# sage:
#   fixed:
#     model.model_type: sage
# appnp:
#   fixed:
#     model.model_type: appnp
#   grid:
#     model.teleportation_probability:
#       type: choice
#       options:
#         - 0.1
#         - 0.2
#         - 0.5
#         - 0.8
#     model.diffusion_iterations:
#       type: choice
#       options:
#         - 2
#         - 5
#         - 10
# mlp:
#   fixed:
#     model.model_type: mlp
  